{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 6, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}},
    {"offset": {"line": 140, "column": 0}, "map": {"version":3,"sources":["file:///Users/senujidesilva/Desktop/Frontend/app/api/health-check/route.ts"],"sourcesContent":["import { NextResponse } from \"next/server\";\nimport OpenAI from \"openai\";\n\nexport async function GET() {\n  try {\n    const openai = new OpenAI({\n      apiKey: process.env.OPENAI_API_KEY,\n    });\n\n    // Send a minimal request to check if the API is responsive\n    await openai.chat.completions.create({\n      model: \"gpt-3.5-turbo\",\n      messages: [{ role: \"user\", content: \"test\" }],\n      max_tokens: 1,\n    });\n\n    return NextResponse.json({ status: \"available\" }, { status: 200 });\n  } catch (error: any) {\n    console.error(\"OpenAI API Health Check Failed:\", error);\n    return NextResponse.json(\n      {\n        status: \"unavailable\",\n        error: error?.message || \"Unknown error occurred\",\n      },\n      { status: 503 }\n    );\n  }\n}\n"],"names":[],"mappings":";;;AAAA;AACA;;;AAEO,eAAe;IACpB,IAAI;QACF,MAAM,SAAS,IAAI,kJAAA,CAAA,UAAM,CAAC;YACxB,QAAQ,QAAQ,GAAG,CAAC,cAAc;QACpC;QAEA,2DAA2D;QAC3D,MAAM,OAAO,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;YACnC,OAAO;YACP,UAAU;gBAAC;oBAAE,MAAM;oBAAQ,SAAS;gBAAO;aAAE;YAC7C,YAAY;QACd;QAEA,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CAAC;YAAE,QAAQ;QAAY,GAAG;YAAE,QAAQ;QAAI;IAClE,EAAE,OAAO,OAAY;QACnB,QAAQ,KAAK,CAAC,mCAAmC;QACjD,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CACtB;YACE,QAAQ;YACR,OAAO,OAAO,WAAW;QAC3B,GACA;YAAE,QAAQ;QAAI;IAElB;AACF","debugId":null}}]
}